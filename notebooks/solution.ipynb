{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ef8b6c",
   "metadata": {},
   "source": [
    "# MPhil DIS: S1 Coursework 2025/26\n",
    "\n",
    "*Your Name (crsid@cam.ac.uk)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ad1b4",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Your college room mate is a Physics student having some trouble with data analysis. \n",
    "\n",
    "They have been asked by their supervisor to determine the performance of a photon detector in their lab. \n",
    "\n",
    "Your friend has diligently collected calibration samples in the lab. They have used a laser setup to produce single photons at known fixed Energies (i.e. frequencies) of $E_0$ = [20, 30, 40, 50, 60, 70, 80] GeV and recorded the measured energy, $E$, of the detector (also in GeV, although the units are irrelevant for this problem). They performed $N=1000$ measurements of the energy recorded by the detector, $E$, at each fixed point $E_0$. (Hint: we may assume the supervisor's lab setup is so sophisticated that the energy uncertainty of the laser itself is negligible - in other words $E_0$ is known exactly with no error). \n",
    "\n",
    "Your friend knows, because they asked ChatGPT, that the measured energy (registered by the detection device),\n",
    "$E$, will be normally distributed, $E\\sim \\mathcal{N}(\\mu_E, \\sigma^2_E)$, with mean, \n",
    "\n",
    "$$\n",
    "\\mu_E = \\lambda E_0 + \\Delta,\n",
    "$$\n",
    "\n",
    "and a width, $\\sigma_E$, given by\n",
    "\n",
    "$$\n",
    "\\left( \\frac{\\sigma_E}{E_0} \\right)^2 = \\left( \\frac{a}{\\sqrt{E_0}} \\right)^2 + \\left( \\frac{b}{E_0} \\right)^2 + c^2.\n",
    "$$\n",
    "\n",
    "Your task is to use the input data provided in `sample.csv` (which contains two columns corresponding to the laser energy, $E_0$, and the measured energy, $E$) to provide estimates of the parameters $\\{ \\lambda, \\Delta, a, b, c\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Import s1_sol package modules\n",
    "from s1_sol.data_loader import load_sample_data, get_residuals, get_residuals_by_energy\n",
    "from s1_sol.statistics import compute_sample_stats, fit_mean_model_least_squares, fit_width_model_least_squares\n",
    "from s1_sol.models import mean_energy_model, width_energy_model, relative_width_squared\n",
    "from s1_sol.fitting import fit_normal_mle, fit_individual_energies, fit_simultaneous_all_energies\n",
    "from s1_sol.plotting import setup_plot_style, plot_residuals_total, plot_residuals_by_energy\n",
    "from s1_sol.bootstrap import bootstrap_sample, run_bootstrap_analysis, compute_bootstrap_confidence_interval\n",
    "from s1_sol.results_manager import ResultsManager\n",
    "\n",
    "# Set up plot styling\n",
    "setup_plot_style()\n",
    "\n",
    "# Create figs directory if it doesn't exist\n",
    "os.makedirs('../figs', exist_ok=True)\n",
    "\n",
    "# Initialize results manager\n",
    "results = ResultsManager()\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the calibration sample\n",
    "df, data_dict, e0_values = load_sample_data('../sample.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} total measurements\")\n",
    "print(f\"Energy points: {e0_values}\")\n",
    "print(f\"\\nMeasurements per energy point:\")\n",
    "for e0 in e0_values:\n",
    "    print(f\"  E0 = {e0} GeV: {len(data_dict[e0])} measurements\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ad4a8",
   "metadata": {},
   "source": [
    "## 1) Plotting Sample Estimates\n",
    "**10 marks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e08fd",
   "metadata": {},
   "source": [
    "### 1(i) plot total sample\n",
    "- Get hold of your data sample, `sample.csv`, and make a plot of the measured energy, `E`, minus the true energy, `E_0`. This plot should be saved in `figs/Figure1.1.pdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-1-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_total(df)\n",
    "fig.savefig('../figs/Figure1.1.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1.1 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2f9a3",
   "metadata": {},
   "source": [
    "### 1(ii) overlay samples at each $E_0$\n",
    "- Make a plot which shows the distribution of `E - E_0`, with the histograms for each different value of `E_0` overlaid. This plot should be saved in `figs/Figure1.2.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-1-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_residuals_by_energy(data_dict)\n",
    "fig.savefig('../figs/Figure1.2.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1.2 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536d675",
   "metadata": {},
   "source": [
    "### 1(iii) sample estimates\n",
    "- Produce sample estimates of the mean, $\\hat{\\mu}_{\\rm samp}$, and standard deviation, $\\hat{\\sigma}_{\\rm samp}$, of $E$ at each value of $E_0$. These should be presented along with sample estimates of the error on these estimates (i.e. the standard error on the mean and the standard error on the standard deviation).\n",
    "- Make two plots (sub-axes of the same figure) showing the points $\\hat{\\mu}_{\\rm samp}$ and $\\hat{\\sigma}_{\\rm samp}$ as a function of $E_0$. This figure should be saved to `figs/Figure1.3.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sample statistics\n",
    "stats_df = compute_sample_stats(data_dict)\n",
    "\n",
    "print(\"Sample Statistics:\")\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-1-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "\n",
    "# Left plot: Sample means vs E0\n",
    "ax[0].errorbar(stats_df['E0'], stats_df['mean'], yerr=stats_df['mean_err'],\n",
    "               fmt='o', capsize=3)\n",
    "ax[0].set_xlabel('$E_0$ [GeV]')\n",
    "ax[0].set_ylabel('$\\\\hat{\\\\mu}_{\\\\rm samp}$ [GeV]')\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: Sample standard deviations vs E0\n",
    "ax[1].errorbar(stats_df['E0'], stats_df['std'], yerr=stats_df['std_err'],\n",
    "               fmt='o', capsize=3, color='C1')\n",
    "ax[1].set_xlabel('$E_0$ [GeV]')\n",
    "ax[1].set_ylabel('$\\\\hat{\\\\sigma}_{\\\\rm samp}$ [GeV]')\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../figs/Figure1.3.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1.3 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310ab8d",
   "metadata": {},
   "source": [
    "### 1(iv) fit trends\n",
    "- Perform a least squares fit using the energy and width dependence formulas provided in the problem description (at the top of this notebook) to produce estimates (and estimates of the errors on those estimates) for the parameters $\\lambda$, $\\Delta$, $a$, $b$ and $c$. Be sure to save these determinations for later or write them directly into the `results.json` file\n",
    "- The previously made plots don't have a particular sensible y-scale. Make two plots (sub-axes of the same figure) showing the points $\\hat{\\mu}_{\\rm samp}$ and $\\hat{\\sigma}_{\\rm samp}$ as a function of $E_0$ **but this time realign the y-scale** so that you plot $\\hat{\\mu}_{\\rm samp} - E_0$ and $\\hat{\\sigma}_{\\rm samp} / E_0$. You should also **overlay the fitted curves** and add error bands ($\\pm 1\\sigma$) to the curves by bootstrapping. This figure should be saved to `figs/Figure1.4.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-sample-ests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit mean model: μ_E = λ·E₀ + Δ\n",
    "lambda_samp, delta_samp, lambda_err_samp, delta_err_samp = fit_mean_model_least_squares(\n",
    "    stats_df['E0'].values, stats_df['mean'].values, stats_df['mean_err'].values\n",
    ")\n",
    "\n",
    "# Fit width model\n",
    "a_samp, b_samp, c_samp, a_err_samp, b_err_samp, c_err_samp = fit_width_model_least_squares(\n",
    "    stats_df['E0'].values, stats_df['std'].values, stats_df['std_err'].values\n",
    ")\n",
    "\n",
    "print(f\"Sample Estimates from Least Squares:\")\n",
    "print(f\"λ = {lambda_samp:.4f} ± {lambda_err_samp:.4f}\")\n",
    "print(f\"Δ = {delta_samp:.4f} ± {delta_err_samp:.4f}\")\n",
    "print(f\"a = {a_samp:.4f} ± {a_err_samp:.4f}\")\n",
    "print(f\"b = {b_samp:.4f} ± {b_err_samp:.4f}\")\n",
    "print(f\"c = {c_samp:.4f} ± {c_err_samp:.4f}\")\n",
    "\n",
    "# Save to results\n",
    "results.update('sample_ests',\n",
    "               {'lb': lambda_samp, 'dE': delta_samp, 'a': a_samp, 'b': b_samp, 'c': c_samp},\n",
    "               {'lb': lambda_err_samp, 'dE': delta_err_samp, 'a': a_err_samp, 'b': b_err_samp, 'c': c_err_samp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-1-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "\n",
    "# Create fine grid for smooth curves\n",
    "e0_smooth = np.linspace(e0_values.min(), e0_values.max(), 100)\n",
    "\n",
    "# Left plot: μ - E0 (rescaled mean)\n",
    "rescaled_mean = stats_df['mean'].values - stats_df['E0'].values\n",
    "rescaled_mean_fit = mean_energy_model(e0_smooth, lambda_samp, delta_samp) - e0_smooth\n",
    "\n",
    "ax[0].errorbar(stats_df['E0'], rescaled_mean, yerr=stats_df['mean_err'],\n",
    "               fmt='ko', capsize=3)\n",
    "ax[0].plot(e0_smooth, rescaled_mean_fit, 'r-', linewidth=2)\n",
    "ax[0].set_xlabel('$E_0$ [GeV]')\n",
    "ax[0].set_ylabel('$\\\\hat{\\\\mu}_{\\\\rm samp} - E_0$ [GeV]')\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right plot: σ/E0 (relative width)\n",
    "relative_width = stats_df['std'].values / stats_df['E0'].values\n",
    "relative_width_err = stats_df['std_err'].values / stats_df['E0'].values\n",
    "relative_width_fit = width_energy_model(e0_smooth, a_samp, b_samp, c_samp) / e0_smooth\n",
    "\n",
    "ax[1].errorbar(stats_df['E0'], relative_width, yerr=relative_width_err,\n",
    "               fmt='ko', capsize=3)\n",
    "ax[1].plot(e0_smooth, relative_width_fit, 'b-', linewidth=2)\n",
    "ax[1].set_xlabel('$E_0$ [GeV]')\n",
    "ax[1].set_ylabel('$\\\\hat{\\\\sigma}_{\\\\rm samp} / E_0$')\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "\n",
    "# TODO: Add bootstrap error bands\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../figs/Figure1.4.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1.4 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f3ff8",
   "metadata": {},
   "source": [
    "## 2) Individual Fits\n",
    "**10 marks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38588dd1",
   "metadata": {},
   "source": [
    "### 2(i) normal fits\n",
    "- Now instead of sample estimates for the mean and width, perform and unbinned maximum likelihood fit of the distribution of $E$ at each value of $E_0$ using a normal distribution to determine the mean, $\\hat{\\mu}_{\\rm indiv}$, and width, $\\hat{\\sigma}_{\\rm indiv}$, (as well as their errors) at each $E_0$\n",
    "- Make two plots (sub-axes of the same figure). The left should show the distribution of $E-E_0$ (with the distribution at each value of $E_0$ overlaid) also overlaying the result of the normal likelihood fits. The right should show the distribution of $E - E_0$ for all values and then overlay the approproiately normalised sum of sub-distributions. This plot should be saved in `figs/Figure2.1.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indiv-fits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit normal distribution at each energy point\n",
    "indiv_fits_df = fit_individual_energies(data_dict)\n",
    "\n",
    "print(\"Individual MLE Fits:\")\n",
    "print(indiv_fits_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-2-1",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n\nfrom scipy.stats import norm\n\n# Define bin edges for histograms\nbin_edges = np.linspace(-10, 15, 60)\nbin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\nbin_width = bin_edges[1] - bin_edges[0]\n\n# Left plot: Overlaid histograms with fitted curves for each E0\nfor i, e0 in enumerate(e0_values):\n    residuals = data_dict[e0] - e0\n    \n    # Get fitted parameters for this energy\n    mu_fit = indiv_fits_df[indiv_fits_df['E0'] == e0]['mu'].values[0]\n    sigma_fit = indiv_fits_df[indiv_fits_df['E0'] == e0]['sigma'].values[0]\n    \n    # Plot histogram\n    ax[0].hist(residuals, bins=bin_edges, alpha=0.3, label=f'$E_0={int(e0)}$ GeV', density=True)\n    \n    # Overlay fitted normal distribution\n    x_smooth = np.linspace(-10, 15, 200)\n    fitted_pdf = norm.pdf(x_smooth, mu_fit - e0, sigma_fit)\n    ax[0].plot(x_smooth, fitted_pdf, linewidth=2)\n\nax[0].set_xlabel('$E - E_0$ [GeV]')\nax[0].set_ylabel('Density')\nax[0].legend(fontsize=8, loc='upper right')\nax[0].grid(True, alpha=0.3)\n\n# Right plot: Total histogram with sum of fitted distributions\nall_residuals = df['E_rec'].values - df['E_true'].values\nax[1].hist(all_residuals, bins=bin_edges, alpha=0.5, label='All data', density=True, color='gray')\n\n# Calculate and plot the sum of fitted distributions\nx_smooth = np.linspace(-10, 15, 200)\ntotal_pdf = np.zeros_like(x_smooth)\n\nfor i, e0 in enumerate(e0_values):\n    mu_fit = indiv_fits_df[indiv_fits_df['E0'] == e0]['mu'].values[0]\n    sigma_fit = indiv_fits_df[indiv_fits_df['E0'] == e0]['sigma'].values[0]\n    \n    # Each E0 contributes 1/7 of the total (equal number of measurements)\n    fitted_pdf = norm.pdf(x_smooth, mu_fit - e0, sigma_fit) / len(e0_values)\n    total_pdf += fitted_pdf\n\nax[1].plot(x_smooth, total_pdf, 'r-', linewidth=2, label='Sum of fitted distributions')\nax[1].set_xlabel('$E - E_0$ [GeV]')\nax[1].set_ylabel('Density')\nax[1].legend()\nax[1].grid(True, alpha=0.3)\n\nfig.tight_layout()\nfig.savefig('../figs/Figure2.1.pdf')\nplt.show()\n\nprint(\"Figure 2.1 saved.\")"
  },
  {
   "cell_type": "markdown",
   "id": "f3bd9abe",
   "metadata": {},
   "source": [
    "### 2(ii) fit trends\n",
    "- Perform a least squares fit using the energy and width dependence formulas provided in the problem description (at the top of this notebook) to produce estimates (and estimates of the errors on those estimates) for the parameters $\\lambda$, $\\Delta$, $a$, $b$ and $c$. Be sure to save these determinations for later or write them directly to the `results.json` file.\n",
    "- Make two plots (sub-axes of the same figure) showing the fitted values $\\hat{\\mu}_{\\rm indiv} - E_0$ and $\\hat{\\sigma}_{\\rm indiv}/E_0$ as a function of $E_0$ **as well as** the fitted curves. You should add an error band ($\\pm 1\\sigma$) to the curves by bootstrapping. This figure should be saved to `figs/Figure2.2.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-indiv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the least squares functions on the individual fit results\n",
    "lambda_indiv, delta_indiv, lambda_err_indiv, delta_err_indiv = fit_mean_model_least_squares(\n",
    "    indiv_fits_df['E0'].values, indiv_fits_df['mu'].values, indiv_fits_df['mu_err'].values\n",
    ")\n",
    "\n",
    "a_indiv, b_indiv, c_indiv, a_err_indiv, b_err_indiv, c_err_indiv = fit_width_model_least_squares(\n",
    "    indiv_fits_df['E0'].values, indiv_fits_df['sigma'].values, indiv_fits_df['sigma_err'].values\n",
    ")\n",
    "\n",
    "print(f\"Individual Fits + Least Squares:\")\n",
    "print(f\"λ = {lambda_indiv:.4f} ± {lambda_err_indiv:.4f}\")\n",
    "print(f\"Δ = {delta_indiv:.4f} ± {delta_err_indiv:.4f}\")\n",
    "print(f\"a = {a_indiv:.4f} ± {a_err_indiv:.4f}\")\n",
    "print(f\"b = {b_indiv:.4f} ± {b_err_indiv:.4f}\")\n",
    "print(f\"c = {c_indiv:.4f} ± {c_err_indiv:.4f}\")\n",
    "\n",
    "# Save to results\n",
    "results.update('individual_fits',\n",
    "               {'lb': lambda_indiv, 'dE': delta_indiv, 'a': a_indiv, 'b': b_indiv, 'c': c_indiv},\n",
    "               {'lb': lambda_err_indiv, 'dE': delta_err_indiv, 'a': a_err_indiv, 'b': b_err_indiv, 'c': c_err_indiv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-2-2",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n\n# Create fine grid for smooth curves\ne0_smooth = np.linspace(e0_values.min(), e0_values.max(), 100)\n\n# Left plot: μ_indiv - E0 (rescaled mean)\nrescaled_mean_indiv = indiv_fits_df['mu'].values - indiv_fits_df['E0'].values\nrescaled_mean_fit = mean_energy_model(e0_smooth, lambda_indiv, delta_indiv) - e0_smooth\n\nax[0].errorbar(indiv_fits_df['E0'], rescaled_mean_indiv, yerr=indiv_fits_df['mu_err'],\n               fmt='ko', capsize=3, label='Individual fits')\nax[0].plot(e0_smooth, rescaled_mean_fit, 'r-', linewidth=2,\n           label=f'Fit: λ={lambda_indiv:.4f}, Δ={delta_indiv:.4f}')\nax[0].set_xlabel('$E_0$ [GeV]')\nax[0].set_ylabel('$\\\\hat{\\\\mu}_{\\\\rm indiv} - E_0$ [GeV]')\nax[0].legend()\nax[0].grid(True, alpha=0.3)\n\n# Right plot: σ_indiv/E0 (relative width)\nrelative_width_indiv = indiv_fits_df['sigma'].values / indiv_fits_df['E0'].values\nrelative_width_err_indiv = indiv_fits_df['sigma_err'].values / indiv_fits_df['E0'].values\nrelative_width_fit = width_energy_model(e0_smooth, a_indiv, b_indiv, c_indiv) / e0_smooth\n\nax[1].errorbar(indiv_fits_df['E0'], relative_width_indiv, yerr=relative_width_err_indiv,\n               fmt='ko', capsize=3, label='Individual fits')\nax[1].plot(e0_smooth, relative_width_fit, 'b-', linewidth=2,\n           label=f'Fit: a={a_indiv:.4f}, b={b_indiv:.4f}, c={c_indiv:.4f}')\nax[1].set_xlabel('$E_0$ [GeV]')\nax[1].set_ylabel('$\\\\hat{\\\\sigma}_{\\\\rm indiv} / E_0$')\nax[1].legend()\nax[1].grid(True, alpha=0.3)\n\n# TODO: Add bootstrap error bands (will be done in Section 4)\n\nfig.tight_layout()\nfig.savefig('../figs/Figure2.2.pdf')\nplt.show()\n\nprint(\"Figure 2.2 saved.\")"
  },
  {
   "cell_type": "markdown",
   "id": "147956f5",
   "metadata": {},
   "source": [
    "## 3.) Simultaneous Fit\n",
    "**10 marks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a81d2d",
   "metadata": {},
   "source": [
    "### 3(i) the simultaneous likelihood\n",
    "- Write down an equation for the simultaneous likelihood in which all points are fitted together, i.e. directly fitting the sample for $\\lambda$, $\\Delta$, $a$, $b$ and $c$\n",
    "- Appropriately code this and perform an unbinned maximum likelihood fit to all $E_0$ bins simultaneously, to produce estimates (and estimates of the errors on those estimates) for the parameters $\\lambda$, $\\Delta$, $a$, $b$ and $c$. Be sure to save these determinations for later or write them directly to the `results.json` file.\n",
    "- Make two plots (sub-axes of the same figure) showing the fitted curves for $\\mu_E$ and $\\sigma_E$ as a function of $E_0$. You should add an error band ($\\pm 1\\sigma$) to the curves by bootstrapping. You should stick to the convention of plotting $\\mu_E - E_0$ and $\\sigma_E / E_0$ as a function of $E_0$. This figure should be saved to `figs/Figure3.1.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simul-likelihood-eq",
   "metadata": {},
   "source": [
    "The simultaneous likelihood:\n",
    "\n",
    "$$\\mathcal{L}(\\lambda, \\Delta, a, b, c) = \\prod_{i=1}^{7} \\prod_{j=1}^{1000} \\frac{1}{\\sqrt{2\\pi}\\sigma_E(E_{0,i})} \\exp\\left[-\\frac{(E_{ij} - \\mu_E(E_{0,i}))^2}{2\\sigma_E^2(E_{0,i})}\\right]$$\n",
    "\n",
    "where $\\mu_E(E_0) = \\lambda E_0 + \\Delta$ and $\\sigma_E(E_0) = E_0 \\sqrt{(a/\\sqrt{E_0})^2 + (b/E_0)^2 + c^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simul-fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform simultaneous fit\n",
    "params_simul, errors_simul, minuit_obj = fit_simultaneous_all_energies(data_dict)\n",
    "\n",
    "print(\"Simultaneous Fit Results:\")\n",
    "print(f\"λ = {params_simul['lam']:.4f} ± {errors_simul['lam']:.4f}\")\n",
    "print(f\"Δ = {params_simul['delta']:.4f} ± {errors_simul['delta']:.4f}\")\n",
    "print(f\"a = {params_simul['a']:.4f} ± {errors_simul['a']:.4f}\")\n",
    "print(f\"b = {params_simul['b']:.4f} ± {errors_simul['b']:.4f}\")\n",
    "print(f\"c = {params_simul['c']:.4f} ± {errors_simul['c']:.4f}\")\n",
    "print(f\"\\nFit valid: {minuit_obj.valid}\")\n",
    "print(f\"Fit accurate: {minuit_obj.accurate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-3-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "\n",
    "# TODO: Add fitted curves with bootstrap error bands\n",
    "\n",
    "fig.savefig('../figs/Figure3.1.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 3.1 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c92f02",
   "metadata": {},
   "source": [
    "### 3(ii) saving the results\n",
    "- At this point you should have estimates of the five parameters, $\\{\\lambda, \\Delta, a, b, c\\}$, (along with their errors), using three different methods: \"a sample estimate\", \"individual fits\" and \"a simultaneous fit\".\n",
    "- Ensure these are now saved into the `results.json` file in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update results with simultaneous fit\n",
    "results.update('simultaneous_fit',\n",
    "               {'lb': params_simul['lam'], 'dE': params_simul['delta'],\n",
    "                'a': params_simul['a'], 'b': params_simul['b'], 'c': params_simul['c']},\n",
    "               {'lb': errors_simul['lam'], 'dE': errors_simul['delta'],\n",
    "                'a': errors_simul['a'], 'b': errors_simul['b'], 'c': errors_simul['c']})\n",
    "\n",
    "# Save results.json\n",
    "results.save('../results.json')\n",
    "\n",
    "# Display results\n",
    "results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42389b",
   "metadata": {},
   "source": [
    "### 3(iii) comparing the results\n",
    "- Make a plot which shows the estimate and error of each parameter, labelling the different estimation types with different colours.\n",
    "- The parameters may well have rather different values so you will need to think carefully about how you present this information in a sensible way.\n",
    "- You should save this in a file called `figs/Figure3.2.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-3-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.4, 6.4))\n",
    "\n",
    "# TODO: Add comparison plot of all three methods\n",
    "\n",
    "fig.savefig('../figs/Figure3.2.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 3.2 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5daca8",
   "metadata": {},
   "source": [
    "## 4.) Bootstrap entire sample\n",
    "**20 marks**\n",
    "- Run a non-parameteric bootstrap on the entire analysis using sampling with replacement (and 2500 samples). For reference on my machine this takes ~1 min)\n",
    "- Produce a figure with 5 subfigures which shows histograms of the bootstrapped values with each method overlaid as a separate colour. You should save this plot in a file called `figs/Figure4.1.pdf`\n",
    "- Produce a second figure which is the same in style to the plot produced in 3(iii) above this time using the bootstrapped sample to estimate the value and error. You should overlay both sets of points (i.e. the values and errors from parts 1-3 and also the bootstrapped values and errors from part 4). You should save this plot in a file called `figs/Figure4.2.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement bootstrap analysis\n",
    "\n",
    "# def analysis_function(bootstrap_data):\n",
    "#     # Run all three methods on bootstrap sample\n",
    "#     # Return dict with all parameters\n",
    "#     pass\n",
    "\n",
    "# bootstrap_results = run_bootstrap_analysis(data_dict, analysis_function, n_bootstrap=2500)\n",
    "\n",
    "print(\"TODO: Implement bootstrap analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-4-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(19.2, 9.6))\n",
    "\n",
    "# TODO: Add bootstrap histograms\n",
    "\n",
    "ax[0,0].set_xlabel(\"$\\\\lambda$\")\n",
    "ax[0,1].set_xlabel(\"$\\\\Delta$\")\n",
    "ax[0,2].set_visible(False)\n",
    "ax[1,0].set_xlabel(\"$a$\")\n",
    "ax[1,1].set_xlabel(\"$b$\")\n",
    "ax[1,2].set_xlabel(\"$c$\")\n",
    "\n",
    "fig.savefig('../figs/Figure4.1.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 4.1 saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig-4-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.4, 6.4))\n",
    "\n",
    "# TODO: Add comparison plot with both original and bootstrap uncertainties\n",
    "\n",
    "fig.savefig('../figs/Figure4.2.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 4.2 saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195ab86",
   "metadata": {},
   "source": [
    "## 5.) Discussion of Results\n",
    "**20 marks**\n",
    "\n",
    "- Please briefly discuss your findings in no more than 500 words. Do you find what you would naively expect? Can you comment on any discrepancies you see? Would you redesign the analysis in any way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discussion",
   "metadata": {},
   "source": [
    "TODO: Add your discussion here (maximum 500 words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}